<!DOCTYPE html>
<html lang="en">
<head>
    <title>BSUSP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta charset="UTF-8" />
    <meta name="author" content="MCKerim" />
    <link rel="stylesheet" href="style.css" />
</head>

<body>
<!--    ALLGEMEINE FRAGEN    -->
<h1>1. Allgemeine Fragen</h1>

<div class="themeSection">
    <h2>
        Busmaster- vs. programmed I/O-Datentransfer
    </h2>
    <p>
        Gerätesteuerung: CPU startet E/A-Auftrag durch Programmierung von Geräteregistern <br>
        z.B: Kontrollregister, Statusregister, Befehlsregister, Datenregister, Indexregister, Datenpuffer(Anbindung per Busmastertransfer)
    </p>
    <h3>Programmed I/O:</h3>
    <p>
        -CPU überträgt wortweise Daten aus Hauptspeicher zum Gerät <br>
        <span class="negativ">-i.d.R. nicht verwendet (Sehr Langsam)</span>
    </p>
    <h3>Busmaster/Direkter Speicherzugriff:</h3>
    <p>
        -CPU startet nur den Datentransfer <br>
        -Eigentliche Übertragung direkt zwischen Hauptspeicher und Gerät <br>
        -Direct Memory Access(DMA) für ISA-Geräte <br>
        -Busmaster-Transfer für PCI-Geräte <br>
        <span class="positiv">-CPU weiterarbeiten während Daten nebenläufig übertragen werden</span>
    </p>
</div>

<div class="themeSection">
    <h2>
        Ausnutzen Pufferüberlauf
    </h2>
    <h3>
        Ursachen
    </h3>
    <p>
        C-Compiler keine Überprüfung von Array/Puffergrenzen <br>
        eigene unsichere Funktionen + unsichere Bibliotheksfunktionen(strcpy, gets)<br>
    </p>
    <h3>
        Denial of Service(DoS)
    </h3>
    <p>
        Programm durch Pufferüberlauf abstürzen lassen
    </p>
    <h3>
        Eigenen Code ausführen
    </h3>
    <p>
        Manipulation des Kontrollfluss oder Code einschleusen, der durch Pufferüberlauf ausgeführt wird <br>
        Fachbegriff: Exploit <br>
        Programm durch standartiput einschleusen und anspringen
    </p>
    <h3>
        Gegenmaßnahme
    </h3>
    <p>
        Sichere Systemaufrufe verwenden: fgets(hat eingabelänge als parameter) <br>
        Mit gcc Stack schützen <br>
        Zufallszahl vor Rücksprungadresse <br>
        Sicherheitskopie der Rücksprungadesse
    </p>
    <h3>
        Wurm
    </h3>
    <p>
        Schadprogramm welches sich selbst vervielfältigt
    </p>
    <h3>
        Maleware
    </h3>
    <p>
        Rootkit, nach Einbruch in ein System installiert, dauerhafte unterwanderung des Systems, Kernel/User basiert
    </p>
</div>

<div class="themeSection">
    <h2>
        Interrupt
    </h2>
    <p>
        Ereignis das sofort ausgeführt werden soll von der CPU<br>
        Das Betriebssystem behandelt Interrupts, indem es den Zustand des Programms sichert, den passenden Interrupt-Handler ausführt und danach den Zustand des Programms wiederherstellt.
    </p>
    <h3>Software-Interrupt</h3>
    <p>
        -Befehl im Programm (z.B: Programm beenden speicher freigeben)
    </p>
    <h3>Hardware-Interrupt</h3>
    <p>
        -Externes Gerät (z.B: Tastendruck Tastatur)
    </p>
</div>

<div class="themeSection">
    <h2>
        Betriebssystem
    </h2>
    <h3>Definition</h3>
    <p>
        -Macht Anwendungen die <span class="marked">Betriebsmittel</span> zugänglich <br>
        -Abwicklung von Programmen steuern und überwachen <br>
        -Brücke zw. Hardware und Anwendungen
    </p>
    <h3>Betriebsmittel</h3>
    <p>
        Ressourcen des Rechensystems <br>
        Physikalische Betriebsmittel: Speicher, CPU, Geräte, ... <br>
        Logische Betriebsmittel: Fenster, Dateien, ...
    </p>
    <h3>Aufgaben</h3>
    <p>
        -Speicherverwaltung <br>
        -Scheduling <br>
        -Ressourcenverwalter <br>
    </p>
    <h3>Ziele</h3>
    <p>
        <span class="marked">Abstraktion:</span> Hardware-unabhängige Schnittstellen <br>
        <span class="marked">Effizienz:</span> Hardware-Ressourcen effektiv bereitstellen <br>
        <span class="marked">Zuverlässigkeit:</span> robustes Ausführen von Programmen <br>
        <span class="marked">Komfort:</span> einfaches Benutzen des Computers <br>
        <span class="marked">Sicherheit:</span> keine unerlaubten zugriffe <br>
        <span class="negativ">Zielkonflikte:
             Komfort vs. Effizienz, 
             Sicherheit vs. Schnelligkeit, ...</span>
    </p>
</div>

<div class="themeSection">
    <h2>
        Mikrokern vs. monolithischen Kern
    </h2>
    <h3>
        Mikrokern Betriebssystem
    </h3>
    <p>
        <span class="positiv">Vorteile:</span><br>
        -Sicherheit, Stabilität <br>
        -Flexiblität, Erweiterbarkeit<br>
        -Portierbarkeit<br>
        <span class="negativ">Nachteile:</span><br>
        -Langsamer (mehr Kontextwechsel nötig)<br>
        <br>
    <pre>
    +---------------------+
    |   Nutzerprozesse    |
    |  +---------------+  |
    |  |   Dienste     |  |
    |  +---------------+  |
    |  +---------------+  |
    |  |   Treiber     |  |
    |  +---------------+  |
    +---------------------+
    |      Mikrokern      |
    +---------------------+
    </pre>
    </p>
    <h3>
        Monolithischen Kernel Betriebssystem
    </h3>
    <p>
        <span class="positiv">Vorteile:</span><br>
        -Geschwindigkeit<br>
        <span class="negativ">Nachteile:</span><br>
        -Weniger Sicherheit<br>
        <br>
    <pre>
    +---------------------+
    |   Nutzerprozesse    |
    +---------------------+
    |                     |
    |                     |
    |    Monolithischer   |
    |       Kernel        |
    |                     |
    |                     |
    +---------------------+
    </pre>
    </p>
    
</div>

<div class="themeSection">
    <h2>
        Systemaufruf
    </h2>
    <p>
        Für sehr schnelle Ein- und Ausgaben will man das Umkopieren der Daten zwischen Userund Kernel-Mode vermeiden. Welcher Systemaufruf wird hierfür unter UNIX verwendet
        und was passiert dabei?
    </p>
</div>

<!--    SCHEDULING    -->
<h1>2. Scheduling</h1>

<div class="themeSection">
    <h2>
        Reentranter Code
    </h2>
    <p>
        -preemptiver CPU-Entzug kann jederzeit erfolgen <br>
        -von mehreren Threads gleichzeitig ausführbarer Code <br>
        -arbeitet korrekt egal wo unterbrochen <br>
        -muss ggf. synchronisiert werden <br>
        --globale Variablen vermeiden, weil werden geteilt auf Heap <br>
        --Zuständ des Threads als lokale var aufm Stack, da jeder Thread hat sein eigenen Stack <br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Prozess vs. Thread
    </h2>
    <h3>Prozess</h3>
    <p>
        -Programm in Ausführung<br>
        -Kann mehrere Threads enthalten, mind. 1<br>
        -Eigenen Adressraum<br>
        -Ressourcenintensiever<br>
        -Umschalten zwischen Prozessen langsamer(Chaches gespült, Adressraum laden...)<br>
        
    </p>
    <h3>Process Controll Block (PCB)</h3>
    <p>
        Verwaltet im Kernel-Space
    </p>
    <pre>
    +---------------------+
    |        PID          | -> Eindeutig
    +---------------------+
    |    Programmname     |
    +---------------------+
    |     Adressraum      |\
    +---------------------+ | -> Zustandsinformationen
    |   Betriebsmittel    |/-> geöffnete Dateien/Geräte, zum aufräumen
    +---------------------+
    |     Priorität       |
    +---------------------+
    |     UID und GID     |
    +---------------------+
    </pre>
    <h3>Thread</h3>
    <p>
        -Teil eines Prozesses<br>
        -unabhängig con anderen Threads ausführbar<br>
        -Hat eigenen Befehlszeiger(Programmfluss)<br>
        -Hat eigenen Stack<br>
        -Teilt sich Heap/Speicher und andere Ressourcen<br>
        -Leightwheigt Process<br>
        -Für nebenläufige verarbeitung, geht mit Prozessen(fork & pipes) aber schwergewichtig<br>
        -Warten auf I/O geräte, parallele Berechnung auf mehreren Cores, parallele Einzelaufgaben, http-Requests
    </p>
    <h3>Thread Controll Block (TCB)</h3>
    <p>
        Verwaltet im Kernel-Space
    </p>
    <pre>
    +---------------------+
    |        TID          |
    +---------------------+
    |    PCB *process     | -> Pointer auf PCB
    +---------------------+
    | Instruction Pointer |\
    +---------------------+ |
    |        Stack        | | -> Threadzustand (Register, gesichert)
    +---------------------+ |
    |  Weitere Register   |/
    +---------------------+
    |     Priorität       |
    +---------------------+
    |   Ausführungszeit   | -> Wie lange gerechnet
    +---------------------+
    </pre>
</div>

<div class="themeSection">
    <h2>
        Prioritätsinversion
    </h2>
    <p>
        <pan class="marked">Grund:</pan><br>
        Wenn ein Prozess mit niedriger Priorität eine Ressource exklusiv belegt hat,<br>
        die von einem Prozess mit höherer Priorität benötigt wird.<br>
        Dies führt dazu, dass der Job mit höherer Priorität warten muss und somit seine Priorität nicht mehr berücksichtigt wird.<br>
        <pan class="marked">Lösung:</pan><br>
        Eine Methode zur Behebung ist <span class="marked">Prioritätsvererbung</span><br>
        Hierbei erbt der Job mit niedriger Priorität vorübergehend die höhere <br>
        Priorität des wartenden Jobs und kann somit seine Arbeit schneller beenden und die Ressource freigeben.<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Präemptiver Multitasking
    </h2>
    <p>
        Wie CPU entzogen?<br>
        “Context Switch”, bei dem der Zustand des aktuellen Prozesses gespeichert und der Zustand des nächsten Prozesses geladen wird.
    </p>
</div>

<div class="themeSection">
    <h2>
        Threadzustandsdiagramm
    </h2>
    <p>
        -Skizzieren
    </p>
</div>

<div class="themeSection">
    <h2>
        Completely Fair Scheduler
    </h2>
    <p>
        Linux verwendet unter anderem den Completely Fair Scheduler. Erklären Sie dessen Funktionsweise.
        Gehen Sie darauf ein, wie die rechenbereiten Threads verwaltet, wie ein Thread ausgewählt wird und
        wie die Prioriäten dynamisch angepasst werden
    </p>
</div>

<div class="themeSection">
    <h2>Ablaufplan</h2>
    <h3>Rate Monotonic Scheduling(RMS)</h3>
    <p>
        Wiederholen immer wieder
    </p>
    <h3>Round-Robin(RR)</h3>
    <p>
        Zeitscheibenverfahren danach abwechsekn
    </p>
    <h3>Earliest-Deadline-First(EDF)</h3>
    <p>
        Erste Deadline erster
    </p>
    <h3>Completely Fair Scheduler(CFS)</h3>
    <p>
        Erste Deadline erster
    </p>
    <p>
        -Reserve-Plan?
    </p>
    <p>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2223_Klausur1.pdf" target="blank">
            1. KLAUSUR 2023
        </a> 
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
            1. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_1.pdf" target="blank">
            1. KLAUSUR 2021
        </a>
    </p>
</div>


<!--   SPEICHERVERWALTUNG   -->
<h1>3. Speicherverwaltung</h1>

<div class="themeSection">
    <h2>
        Speicherhierarchie
    </h2>
    <p>
        Sekunder/Primärspeicher<br>
        Unterschiedliche Speicherarten in einem Computer(SSD, RAM, Cach, ...)<br>
        Persistenz, schnelligkeit, wahlfreier zugriff(Random Access), Sequentieller Zugriff(schneller), Kapazität
    </p>
    <h2>
        Anforderungen
    </h2>
    <p>
        Mehrprogrammbetrieb: Teilen sich Arbeitsspeicher<br>
        unklar welche/wie viele Programme geladen werden<br>
        <span class="marked">Zuteilung Speicherblöcke: </span> malloc, schnell, wenig Verschnitt<br>
        <span class="marked">Freigabe Speicherblöcke: </span> free, aufräumen beim Terminieren, manuelles/automatisches Einsammeln<br>
        Aus/Einlagern inaktiver Prozesse<br>
        <span class="marked">Relozierung: </span>mithilfe virtueller Speicherverwaltung Prozess an anderen adressen Einlagerbar machen<br>
    </p>
    <h2>
        Begriffe
    </h2>
    <p>
        <span class="marked">Speicherblock: </span>Menge fortlaufender Speicheradressen<br>
        <span class="marked">Partition: </span>Gesamtspeicherblock für Programm(nicht Festplatte Partition)<br>
        <span class="marked">Swapping: </span>Aus/Einlagern von Programmen/Partitionen auf Sekunderspeicher<br>
        <span class="marked">Physikalische(absolute) Speicheradresse: </span>zeigt in physisch vorhandenen Arbeitsspeicher<br>
        <span class="marked">Logische Speicheradresse: </span>Pos. im Arbeitsspeicher aus sicht des Programms, unabh. von phys. Speicherorganisation<br>
        <span class="marked">Relative Speicheradresse: </span>Pos. relativ zu einem bekannten Punkt im Programm(i.d.R. Instruction-Pointer)<br>
    </p>

    <h2>
        Partitionen im Arbeitsspeicher
    </h2>
    <p>
        Aufteilung des Arbeitsspeichers in gleich/variable große Partitionen für je ein Programm damit gleichzeitig ausführbar sind<br>
        Bestandteile:<br>
        <span class="marked">Stack: </span> Funktionsaufrufe(Parameter, lokale Var.)<br>
        <span class="marked">Heap: </span> Dyn. allozierte Daten(malloc), Heap Blöcke: Header(Länge, Flags, Anzahl eleArray, Typ Zeiger), Nutzdaten<br>
        <span class="marked">Globals: </span> globale Var.<br>
        <span class="marked">Text: </span> Code<br>
    </p>
    <h3>
        Statische Partitionierung
    </h3>
    <p>
        während Laufzeit nicht änderbar<br>
        Programm erhält kleinste in das es hineinpasst<br>
        Programm wartet in Zuteilungswarteschlange(für jede Patitionsgröße)<br>
        BS belegt auch eine Partition<br>
        <span class="positiv">Vorteil: </span>Einfach implementierbar, keine Externe Fragmentierung<br>
        <span class="negativ">Nachteil: </span>Max. #Prozesse statisch festgelegt, evt. passt Programm nirgends rein, Speicherbedarf eines Programms muss bekannt sein, Interne Fragmentierung<br>
    </p>
    <h3>
        Dynamische Partitionierung
    </h3>
    <p>
        Länge, Anzahl, Anfangsadressen der Partitionen ändert sich dynamisch<br>
        Programm erhält genauso viel Speicher wie benötigt<br>
        <span class="positiv">Vorteil: </span>Keine Interne Fragmentierung<br>
        <span class="negativ">Nachteil: </span>Externe Fragmentierung -> kann durch Neuanordungn behoben werden, aufwendig weil viele verschieben, gelöst durch virtuelle Speicherverwaltung<br>
    </p>

    <h2>
        Verwaltung freien Speichers
    </h2>
    <p>
        Bei Freigabe: prüfen ob Nachblöcke frei -> zusammenfassen<br>
    </p>
    <h3>
        Bitvektor/Bitmap
    </h3>
    <p>
        Speicher unterteilt(feste länge: 512B, 4KB)<br>
        Jeder bit repräsentiert ob einheit full oder nicht: 111001101111000101<br>
        Je kleiner einheit -> größer Bitvektor, Je größer -> interne Fragmentierung<br>
        <span class="positiv">Vorteil: </span>Kompakt<br>
        <span class="negativ">Nachteil: </span>Allokation langsam -> muss nach nullfolgen suchen<br>
    </p>
    <h3>
        Freispeichertabelle
    </h3>
    <p>
        Freie Blöcke in Tabelle verwaltet: Größe | Adresse<br>
        <span class="positiv">Vorteil: </span>Können var. längen haben <br>
    </p>

    <h3>
        Freispeicherliste(Beste)
    </h3>
    <p>
        Freie Heap-Blöcke mit Zeiger verkettet<br>
        evt. mehrere Listen für vers. größen<br>
        <span class="positiv">Vorteil: </span>Benötigt kein Speicher<br>
    </p>
    <h3>
        Buddy-System
    </h3>
    <p>
        <span class="marked">Buddys: </span>Zwei gleichgroße benachbarte blöcke<br>
        Speicher besteht asud 2^kmax Einheiten<br>
        Speichervergabe in Blockgrößen 2^k<br>
        Jeweils Liste für Blöcke der Größe 2^k<br>
        verw. Linux für Physikalische Speicher<br>
        <span class="positiv">Vorteil: </span>Schnelles verschmelzen<br>
        <span class="negativ">Nachteil: </span>interne u. externe Fragmentierung<br>
    </p>
    <h4>
        Allokation
    </h4>
    <p>
        1. Aufrunden auf nächste Zweierpotenz 1000Bytes -> 1024<br>
        2. Erstes freies Stück aus Liste 2^i<br>
        3. Falls 2^i leer(rekursiv): nächste Größe, halbieren, vordere hälfte zuteilen, hintere liste 2^i anhängen<br>
    </p>
    <h4>
        Freigabe
    </h4>
    <p>
        1. Buddy bestimmen<br>
        2. Falls belegt -> in liste einhängen, stoppen<br>
        3. Falls frei -> Vereinigen, gehe zu 1<br>
    </p>
    <h2>
        Auswahlstrategien freier Blöcke
    </h2>
    <p>
        Kriterien: Fragmentierung, Geschwindigkeit
    </p>
    <h3>
        First-Fit
    </h3>
    <p>
        nimmt ersten groß genug, evt. teilen, Ohne: interne Frag. Mit: externe Frag.<br>
        <span class="positiv">Vorteil: </span>Schnell<br>
        <span class="negativ">Nachteil: </span>Konzentration belegter stücke am Anfang<br>
    </p>
    <h3>
        Next-Fit
    </h3>
    <p>
        zyklisch durchlaufen: beginnt dort wo letzte aufgehört<br>
    </p>
    <h3>
        Best-Fit
    </h3>
    <p>
        Block der am wenigsten Speicherverschnitt verursacht<br>
        Freispeicherliste einmal komplett durchlaufen<br>
        <span class="negativ">Nachteil: </span>Bei zerschneidung seht kleine Stücke<br>
    </p>
    <h3>
        Worst-Fit
    </h3>
    <p>
        Nimm größten Block -> nach zerschneiden noch brauchbar
    </p>

    <h2>
        Interne und externe Fragmentierung/Verschnitt
    </h2>
    <h3>
        Interne Fragmentierung
    </h3>
    <p>
        Programm bekommt mehr speicher zugeteilt als nötig
    </p>
    <h3>
        Externe Fragmentierung
    </h3>
    <p>
        Kleine unbrauchbare Speicherblöcke bleiben übrig
    </p>
</div>

<div class="themeSection">
    <h2>
        Copy-On-Write Konzept
    </h2>
    <p>
        Mehrere Prozesse lesen aus gemeinsamen Speicher<br>
        falls einer schreibt -> Seite kopieren sodass sonst überall gleich bleibt<br>
        Wichtig bei Fork<br>
        müssen nicht alle Daten kopiert werden, nur Seitentabellen<br>
        alle Seitentabelleneinträge auf read only setzen<br>
        Schreibt einer -> protection Fault -> BS aktivieren -> Kopie erstellen<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Garbage Collection (Autom. Freispeichersammlung)
    </h2>
    <p>
        Garbage: Kein Pfad zwischen betrachteten Speicherblock und einem Wurzelzeiger<br>
        Nich adressiebare Blöcke autom. identifizieren u. freigeben(Programm oder Systemweit)<br>
        Expliziete Rückgabe durch Programmierer fehlerhaft und mühsam<br>
        -Abbau komplexer Struckturen<br>
        -Speicherlecks(Memory Leaks): vergessen freizugeben<br>
        -ungültige Zeiger(dangling pointers): zu früh<br>
    </p>
    <h3>
        GC-Phasen
    </h3>
    <p>
        1.Phase: Garbage Detection<br>
        2.Phase: Garbage Reclamation<br>
    </p>
    <h3>
        Vorraussetzungen
    </h3>
    <p>
        Referenzen müssen identifiezierbar sein<br>
        Typsichere Sprache<br>
        GC muss Aufbau eines Speicherblocks und der Stackframes kennen(Wo zeiger, wo andere Variablen)<br>
        -Die Info speichert Compiler in Symboltabelle
    </p>
    <h3>
        Wo Anfangen?
    </h3>
    <p>
        Bei Wurzel-Zeiger(root set): Menge aller gültigen Zeigervariablen, Zeiger in globalen Variablen, Alle Zeiger im Stack<br>
    </p>
    <h3>
        Mark & Sweep Algorithmus
    </h3>
    <p>
        Mark: Markiert alle erreichbaren Blöcke im Heap von Wurzelzeigern<br>
        Makierungsphase muss in einem Stück zu Ende laufen<br>
        werden im Header makiert<br>
        Für jeden Wurzelzeiger z:<br>
        Makiere(z)<br>

        <span class="positiv">Vorteil: </span>Einfach implementiert, Zyklen werden erkannt<br>
        <span class="negativ">Nachteil: </span>Tiefe Rekursion -> viel Speicher im Keller, Heap wird nicht kompaktiert<br>

        Makiere(block):<br>
         wenn block markiert dann beende funktion<br>
         block.mark = 1<br>
         für jeden block den block ref:<br>
         Markiere(block)<br>

        Sweep:<br>
        für jeden Block b, b.mark = 0:<br>
            Speicherfreigabe(b)<br>
        Skizze:
    </p>
    <img src="../../NotUsedImg/MarkAndSweep.png">
    <h3>
        Vorraussetzung <br>
        Mithilfe Skizze wie Mark-And-Swepp-Collector funktioniert <br>
        beschreiben wie Copying-Collector funkt.
    </h3>

    <h3>
        Inkrementeller Mark & Sweep Algorithmus
    </h3>
    <p>
        Nebenläufiges(unterbrechbar)<br>
        Blau: Block komplett untersucht<br>
        Rot: Noch nicht inspiziert<br>
        Grün: Bereits besucht aber nicht alle Nachfolger<br>
        Terminiert wenn keine grünen Blöcke mehr<br>
        Erfordert überwachung von Zeigerzuweisung(Wenn blauer block aufeinmal roten block ref.)<br>
    </p>
    <h3>
        Kopierende Freispeichersammlung(Copying-Collector)
    </h3>
    <p>
        
        Heap in alt und neu unterteilen<br>
        Alle erreichbaren Blöcke rekursiv in neue Region kopieren<br>
        Garbage bleibt in alter Region<br>
        Bei nächsten GC-Aufruf tauschen<br>
        <span class="positiv">Vorteil: </span>Heap automatisch kompaktifiziert, Speicherallokation einfach(freier Speicher immer ein großer Block), Zyklen eliminiert<br>
        <span class="negativ">Nachteil: </span>Aufwändig viele kleine Blöcke zu kopieren, logische Adressraum halbiert, GC muss atomar komplett durchlaufen<br>
    </p>
    <h3>
        Inkrementeller Copying-Collector
    </h3>
    <p>
        Pro Aufruf vorgegebene Anzahl Blöcke kopieren(nicht zu lange Programm anhalten)<br>
        Iterative Lösung<br>
        Scan-Zeiger: Blöcke bis hier komplett abgearbeitet<br>
        Free-Zeiger: Blöcke zwischen den sind kopiert aber haben noch zeiger in die alte Region<br>
        kopierte alte Blöcke verweisen auf ihre Kopie<br>
        terminiert wenn scan auf free-zeiger trifft<br>
        <span class="positiv">Vorteil: </span>Heap automatisch kompaktifiziert, Speicherallokation einfach(freier Speicher immer ein großer Block), Zyklen eliminiert<br>
        <span class="negativ">Nachteil: </span>Zeigerzuweisung überwachen, Datenzugriffe auf kopierte Blöcke überwachen und syncen<br>
    </p>
    <h3>
        Reference Counting Algorithmus
    </h3>
    <p>
        Jeder Speicherblock hat Referenzzähler<br>
        Garbage wenn Referenzzähler auf null<br>
        Zeigerzuweisung über Laufzeitfunktion<br>
        <span class="positiv">Vorteil: </span>Inkrementelle GC möglich, Garbage sofort freigegeben, einfach implementierbar<br>
        <span class="negativ">Nachteil: </span>Zyklen(könnte ab und zu mark and sweep verwenden), erfordert Aufruf einer Laufzeitroutine<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Paging
    </h2>
    <p>
        logischer(virtueller) Adressraum in gleich große Pages unterteilen<br>
        Physikalischen in gleich große Page Frames(Kacheln)<br>
        -Daten einer Page in ein Page Frame sofern geladen<br>
        Prozesse in viele Pages unterteilt<br>
        Keine externe Fragmentierung<br>
        jeweils 1 logischen(virtuellen) Adressraum pro Prozess<br>
    </p>
    <h2>
        Adressübersetzung
    </h2>
    <h3>
        Einfache Seitentabelle
    </h3>
    <p>
        Pro Prozess eigene Seitentabelle<br>
        <span class="negativ">Nachteil: </span>Großer Speicherverbrauch<br>
        Je 1 Eintrag pro Seite, (Kachelnummer, Präsenz-Bit, dirty&accessed Bit)<br>
        Teil der logischen Adresse bildet Seitennummer<br>
    </p>
    <h3>
        Zweistufige Adressübersetzung
    </h3>
    <p>
        Hierarische Seitentabellen<br>
        Ebene 1: Page Directory/Seitenverzeichnis<br>
        1mal pro Prozess<br>
        Zeigen auf Tabelle Ebene 2 oder leer<br>
        Ebene 2: Page Tabels/Seitentabellen<br>
        können ausgelagert werden<br>
        dynamisch angelegt/gelöscht<br>
        Tabelle Kernel Space für jeden<br>
        Nach Meltdown und Spectre wird BS nicht mehr eingeblendet in Adressraum eigener Adressraum<br>
        32Bit -> 10 Bit Page Dir. -> 10 Bit Page Table -> 12 Bit Offset<br>
        <span class="negativ">Nachteil: </span>Langsamer<br>
    </p>
    <h3>
        Invertierte Seitentabellen
    </h3>
    <p>
        Vollständige Seitentabellen viel zu viele einträge(speicher) pro Prozess<br>
        Besser 1 Eintrag pro Kachel als pro logische Seite<br>
        1. Eintrag Kachel 0, 2. Eintrag Kachel 1...<br>

    </p>
    <h3>
        Translation Lookaside Buffer (TLB)
    </h3>
    <p>
        Puffert übersetzte virtuelle Adressen<br>
        MMU sucht erst hier -> Seitentabellen (Page Fault)-> BS soll einlagern ->(physikalissche Adresse) gucken ob Kachel im Chache -> Arbeitscpeicher<br>
        besonderer Schaltkreis für parallele Vergleiche<br>
        komplett löschen bei Prozess/Adressraumwechsel<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Einlagerungsstrategien
    </h2>
    <h3>
        Demand Paging
    </h3>
    <h3>
        Pre Paging
    </h3>
    <h3>
        Kom. Pre/Demand Paging
    </h3>
    <p>
        Pre zu beginn (Programmcode, statische Daten zb) dann Demand
    </p>
    <h2>
        Page Fault
    </h2>
    <p>
        MMU erkennt Präsenz-Bit gelöscht -> page fault Exeption -> Thread unterbrochen -> Page-Fault-Handler -> lädt Seite vom Sekundärspeicher
    </p>
    <h2>
        Auslagern
    </h2>
    <h3>
        Not recently used
    </h3>
    <p>
        Accssed-Bit | Dirty-Bit<br>
        false | false <br>
        false | True<br>
        True | false <br>
        True | True<br>
    </p>
    <h3>
        First-in, First-out
    </h3>
    <h3>
        Least Recently Used(Zeitstempel)
    </h3>
    <h3>
        Thrashing -> Programm zu wenig Kacheln -> ständig Seitenfehler
    </h3>
</div>


<div class="themeSection">
    <h2>
        Shared Memory
    </h2>
    <p>
        Mehrere logische(virtuelle) Seiten auf gleiche Kacheln<br>
        Zeiger dürfen nur auf shared memory bereich zeigen<br>
        Zeiger gehen nur wenn die an der selben logischen Adresse eingeblendet werden<br>
        Muss beim auslagern mehrere Prozesse beachten(Präsenz bit überall löschen)<br>
    </p>
</div>


<div class="themeSection">
    <h2>
        Lokalitätsprinzip
    </h2>
    <h3>
        Zeitliche Lokalität
    </h3>
    <p>
        Daten in naher Zukunft wieder benutzt(Schleifen)
    </p>
    <h3>
        Räumliche Lokalität
    </h3>
    <p>
        Benachbarte Daten in Chache laden(Programmtext)
    </p>
</div>

<div class="themeSection">
    <h2>
        Übersetzung virtueller Adressen zu physikalischen Adressen <br>
        mit Page-Directories/Page-Tables
    </h2>
    <p>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
    </p>
</div>

<div class="themeSection">
    <h2>
        Address Space Layout Randomization (ASLR)
    </h2>
    <p>
        BS vergibt  Programmen zufällige Adressbereiche -> Adressen nicht deterministisch<br>
        Erschwert Angriffe auf Pufferüberlauf<br>
        mit Flag -no-pie aus machen <br>
        Kann mit Bruteforce trotzdem Code einshleusen<br>
        Raten welche adresse angesprungen wird<br>
        Chancen verbessern durch NOP = No Operation, rutscht rein<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Partition
    </h2>
    <p>
        In Betriebssystemen ohne virtuelle Speicherverwaltung werden einzelnen 
        Programmen sogenannte Partitionen zugeteilt. Skizzieren und erläutern Sie (4 P.)
        den Inhalt einer Partition.
    </p>
</div>

<div class="themeSection">
    <h2>
        Memory Management Unit (MMU)
    </h2>
    <p>
        Funktionseinheit im Prozessor<br>
        Erledigt Adressübersetzung<br>
        Überprüft ob Daten ausgelagert wurden<br>
        ob unerlaubte Zugriffe stattfinden<br>

        Muss die MMU bei aktiviertem Paging für die Adressberechnung immer auf die Seiten-Tabellen
        im Hauptspeicher zugreifen?
    </p>
</div>

<div class="themeSection">
    <h2>
        Virtueller Speicher
    </h2>
    <p>
        Anstatt Dynamische Partitionierung<br>
        -Programme komplett ein/ausgelagert, #Partitionen = Max Prozesse zu einem Zeitpunkt<br>
        -> Prozesse größer als Arbeitsspeicher ausführbar<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Schutzarten Paging x86-Prozessoren
    </h2>
    <p>
        Drei Schutzarten
    </p>
</div>



<!--   DATEISYSTEME   -->
<h1>4. Dateisysteme</h1>
<div class="themeSection">
    <h2>
        Inodes
    </h2>
    <p>
        -Inhalt in einem klassichen UNIX-Dateisystem
    </p>    
</div>

<div class="themeSection">
    <h2>
        NTFS New Technology File System
    </h2>
    <p>
        Welche vier Bestandteile speichert NTFS für eine kurze Datei? <br>
        Wie speichert NTFS eine große Datei? Zeichnen Sie dazu auch ein Bild.<br>
<br>
        Alle Dateiinformationen als Datei gespeichert, auch Metadaten<br>
        64-Bit Adressierung für große Dateien - Kleine Blockgrößen für große Partitionen möglich<br>
        Sicherheit: Zugriffskontrolle pro Benutzer oder Gruppe, optionale Verschlüsselung<br>
        Fehlertoleranz: ist ein Journaling File-System, Logging, RAID-Unterstützung<br>
    </p>        
    <h3>
        Datenstrukturen für eine Datei
    </h3>
    <p>
        <span class="marked">File Object: </span>jeweils für Öffnen einer Datei<br>
        <span class="marked">Stream Control Block: </span>jeweils für geöffneten Stream<br>
        <span class="marked">File Control Block: </span>Datei-Referenz in die Master File Table<br>
        BILD
    </p>
    <h3>
        Dateiverwaltung
    </h3>
    <p>
        Datei Referenz bezeichnet Datei/Verzeichnis in Partition<br>
        Sequenznummer = wird hochgezählt für jede gleiche dateinummer<br>
        Dateinummer = Index in Master File Table(MFT)<br>
    </p>
    <h3>
        Aufbau NTFS Volumen(Partition)
    </h3>
    <p>
        Boot Sector(BSC) = Boot Programm, #Sektoren pro Cluster<br>
        MFT(Master File Table) = Pro Datei/Verzeichnis ein Eintrag, MFT selber auch Datei, ung wie Inode Tabelle<br>
        System Files = Log-Datei(Änderungen an MFT), Volumen Datei(Größe, Name, VersionNummer), Bitmap-Datei(freie/belegte Cluster), Boot-Datei(Größe cluster/MFT Eintrag, Boot-Code), Quota-Tabelle, Bad-Cluster-Datei 
    </p>
    <h3>
        MFT-Eintrag für kurze Datei
    </h3>
    <p>
        attribute code<br>
        standart info(Länge, MS-DOS Attribute, #Hard-Links, Zeitstempel Zugriffe, Sequenznummer der gültigen File-Ref)<br>
        security descriptor: Zugriffskontrolle<br>
        data: DAten direkt in der MFT abgelegt<br>
        file name: in Datei Eintrag & Verzeichnis<br>
    </p>
    <h3>
        MFT-Eintrag für lange Datei
    </h3>
    <p>
        außerhalb der MFT in runs/extens abgelegt<br>
        Datenbereich des MFT-Eintrags enthält nur Zeiger<br>
        Falls 1 MFT nicht genügt, weitere alloziert<br>
    </p>
    <h3>
        Aufbau kurze Verzeichniss
    </h3>
    <p>
        ...
    </p>
</div>

<div class="themeSection">
    <h2>
        Struktur ext2 Partition <br>
        Struktur FAT16 Partition
    </h2>
    <p>
        Skizzieren und erläutern
    </p>        
</div>

<div class="themeSection">
    <h2>
        UNIX-Dateisystemstrukturen
    </h2>
    <p>
        Zeichen: Inodes und Datenblöcke <br>
        für abgebildeten Dateisystembaum <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
    </p>        
</div>

<div class="themeSection">
    <h2>
        UNIX-Dateisysteme
    </h2>
    <p>
        -Welche Semantik hat das Setuid-Bit in UNIX-Dateisystemen? Warum (2 P.)
        sollte dieses Bit aus Sicherheitsgründen nur selten verwendet werden? <br>
        -Im Dateisystem ext4 werden sogenannte Extents verwendet. Erklären Sie, (2 P.) 
        welche Informationen für einen Extent gespeichert werden und nennen Sie 
        einen Vorteil gegenüber der klassischen Multilevel-Index-Allokation 
        (Inodes mit je einem Zeiger auf einen Block) <br>
        -Inhalt eines Inodes einem klassischen UNIX-Dateisystem <br>
        -Im Dateisystem ext4 werden sogenannte Extents verwendet. Erklären Sie, welche Informationen für einen Extent gespeichert werden und nennen Sie einen Vorteil gegenüber der
        klassischen Multilevel-Index-Allokation (Inodes mit je einem Zeiger auf einen Block
    </p>        
</div>

<div class="themeSection">
    <h2>
        FAT16
    </h2>
    <p>
        -Skizzieren Struktur FAT16-Partition <br>
        -Erstellen Sie 
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
            1. Klausur 2022 
            -für den gegebenen Ausschnitt einen Auszug der FAT16-Tabelle, welche 
            die Datei sowie die leeren als auch die defekten nachstehenden Cluster zeigt.
        </a>
    </p>        
</div>


<!--   SYNCHRONISIERUNG   -->
<h1>5. Synchronisierung</h1>
<div class="themeSection">
    <h2>
        Kritische Abschnitte
    </h2>
    <p>
        gemeinsame Var -> Syncen<br>
        max 1 Thread im Kritischem Abschnitt<br>
        Problem: Testen und Setzen des Flags geschieht nicht atomar, könnte während Prüfen/gerade fertig Thread umschalten und dann beide eintreten
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
    </p>        
</div>

<div class="themeSection">
    <h2>
        Lost-update Probleme
    </h2>
    <p>
        Inkrementierung unterbrochen, andere Thread ebenfalls inkrementiert -> 1mal verpasst<br>
    </p>        
</div>

<div class="themeSection">
    <h2>
        Wechselseitiger Ausschluss/mutal exclusion(Mutex)
    </h2>
    <p>
        atomare Test-&-Set-Instruktion<br>
    </p>        
    <pre>
        int lock=0; //0=not locked, 1=locked
        void acquire(){
            while Test_Ans_Set (lock_var); //busy polling
        }

        void release(){
            lock = 0;
        }
    </pre>
    <p>
        In pthread mutex_init(pthread_mutex_t *mutex, NULL);<br>
        pthread_mutex_destroy(*mutex);<br>
        pthread_mutex_lock(*mutex);<br>
        pthread_mutex_unlock(*mutex)<br>
        Bedingungsvariablen:<br>
        statisch: pthread_cond_t cond = PTHREAD_COND_INITIALIZER;<br>
        int pthread_cond_wait(*cond, *mutex);<br>
        Warten wird beendet wenn Signal für Bedingugnsvariable empfangen wird<br>
        Dann versucht Sperre auf Mutex anzufordern -> vllt wieder blockiert<br>
        Wakeup thread highest prio: int pthread_cond_signal(*cond);<br>
        Wakeup all: int pthread_cond_broadcast(*cond);<br>
        Spurious wakeups = wachen einfach so auf manchmal<br>
    </p>
    <pre>
        int my_cond = 0;
        void *threads (void *arg){
            pthread_mutex_lock(&mutex);

            while(!my_condition)
                pthread_cond_wait(&cond, &mutex);
        }
    </pre>
</div>

<div class="themeSection">
    <h2>
        Semaphore
    </h2>
    <p>
        Hauptsignal in Schiffahrt<br>
        hier kein Busy-Polling im gegensatz zu Test&Set, alle wartenden Threads blockiert<br>
        Semaphore mit Werten 0 und 1<br>
        zählende Semaphore mit Werden 0..n<br>
        Funktionen Intern mit Test&Set realisiert<br>
        Haben eine queue für wartende Threads-TCB als Eintrag<br>
    </p>        
    <pre>
        Initialisieren:
        InitSem(semVar);

        Passieren?:
        P(semVar):
        if(semVar > 0){
            semVar = semVar -1
        }else{
            warten auf V(semVar)
        }

        Freigeben:
        V(semVar):
        if(Thread wartet auf semVar)
            anstossen(Thread);
        else
            semVar = semVar + 1;
    </pre>
</div>

<div class="themeSection">
    <h2>
        Leser-Schreiber-Problem mit Semaphoren
    </h2>
    <h3>
        N Leser oder 1 Schreiber parallel erlaubt
    </h3>
    <pre>
        int readcount = 0; //aktive Leser
        semaphore mutex=1, wrt=1;

        Leser(){
            P(mutex); //Mit Leser sync.
            readcount++;
            if(readcount==1) //Kein Leser aktiv
                P(wrt); //Schreiber blockieren
            V(mutex);

            reading();

            P(mutex); //Mit Leser sync.
            readcount--;
            if(readcount == 0) //Keine Leser aktiv
                V(wrt); //Schreiber zulassen
            V(mutex);
        }

        Schreiber(){
            P(wrt); //Nur 1 Schreiber
            writing();
            V(wrt);
        }
    </pre>
    <h3>
        N Erzeuger N Verbraucher
    </h3>
    <pre>
        #include semaphore.h
        int sem_init(sem_t *sem, int pshared, unsigned int value);
        pshared = 0für Threads in ein Prozess != 0 für Prozesse
        P(S): int sem_wait(*sem);
        V(S): int sem_post(*sem);
        int sem_destroy(*sem);
        Beispiel
    </pre>
    <h2>
        Deadlock(Threads blockiert), Livelock(Aktives Warten)
    </h2>
    <p>
        wollen gegenseitig die ressource<br>
    </p>
</div>


<!--   PROGRAMMIERAUFGABE  -->
<h1>6. Programmieraufgabe</h1>
<p>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2223_Klausur1.pdf" target="blank">
        1. KLAUSUR 2023
    </a> 
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
        2. KLAUSUR 2022
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
        1. KLAUSUR 2022
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
        2. KLAUSUR 2021
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_1.pdf" target="blank">
        1. KLAUSUR 2021
    </a>
</p>
</body>
</html>