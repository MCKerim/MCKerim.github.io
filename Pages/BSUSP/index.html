<!DOCTYPE html>
<html lang="en">
<head>
    <title>BSUSP</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta charset="UTF-8" />
    <meta name="author" content="MCKerim" />
    <link rel="stylesheet" href="style.css" />
</head>

<body>
<!--    ALLGEMEINE FRAGEN    -->
<h1>1. Allgemeine Fragen</h1>

<div class="themeSection">
    <h2>
        Busmaster- vs. programmed I/O-Datentransfer
    </h2>
    <p>
        Gerätesteuerung: CPU startet E/A-Auftrag durch Programmierung von Geräteregistern <br>
        z.B: Kontrollregister, Statusregister, Befehlsregister, Datenregister, Indexregister, Datenpuffer(Anbindung per Busmastertransfer)
    </p>
    <h3>Programmed I/O:</h3>
    <p>
        -CPU überträgt wortweise Daten aus Hauptspeicher zum Gerät <br>
        <span class="negativ">-i.d.R. nicht verwendet (Sehr Langsam)</span>
    </p>
    <h3>Busmaster/Direkter Speicherzugriff:</h3>
    <p>
        -CPU startet nur den Datentransfer <br>
        -Eigentliche Übertragung direkt zwischen Hauptspeicher und Gerät <br>
        -Direct Memory Access(DMA) für ISA-Geräte <br>
        -Busmaster-Transfer für PCI-Geräte <br>
        <span class="positiv">-CPU weiterarbeiten während Daten nebenläufig übertragen werden</span>
    </p>
</div>

<div class="themeSection">
    <h2>
        Ausnutzen Pufferüberlauf
    </h2>
    <h3>
        Ursachen
    </h3>
    <p>
        C-Compiler keine Überprüfung von Array/Puffergrenzen <br>
        eigene unsichere Funktionen + unsichere Bibliotheksfunktionen(strcpy, gets)<br>
    </p>
    <h3>
        Denial of Service(DoS)
    </h3>
    <p>
        Programm durch Pufferüberlauf abstürzen lassen
    </p>
    <h3>
        Eigenen Code ausführen
    </h3>
    <p>
        Manipulation des Kontrollfluss oder Code einschleusen, der durch Pufferüberlauf ausgeführt wird <br>
        Fachbegriff: Exploit <br>
        Programm durch standartiput einschleusen und anspringen
    </p>
    <h3>
        Gegenmaßnahme
    </h3>
    <p>
        Sichere Systemaufrufe verwenden: fgets(hat eingabelänge als parameter) <br>
        Mit gcc Stack schützen <br>
        Zufallszahl vor Rücksprungadresse <br>
        Sicherheitskopie der Rücksprungadesse
    </p>
    <h3>
        Wurm
    </h3>
    <p>
        Schadprogramm welches sich selbst vervielfältigt
    </p>
    <h3>
        Maleware
    </h3>
    <p>
        Rootkit, nach Einbruch in ein System installiert, dauerhafte unterwanderung des Systems, Kernel/User basiert
    </p>
</div>

<div class="themeSection">
    <h2>
        Interrupt
    </h2>
    <p>
        Ereignis das sofort ausgeführt werden soll von der CPU<br>
        Das Betriebssystem behandelt Interrupts, indem es den Zustand des Programms sichert, den passenden Interrupt-Handler ausführt und danach den Zustand des Programms wiederherstellt.
    </p>
    <h3>Software-Interrupt</h3>
    <p>
        -Befehl im Programm (z.B: Programm beenden speicher freigeben)
    </p>
    <h3>Hardware-Interrupt</h3>
    <p>
        -Externes Gerät (z.B: Tastendruck Tastatur)
    </p>
</div>

<div class="themeSection">
    <h2>
        Betriebssystem
    </h2>
    <h3>Definition</h3>
    <p>
        -Macht Anwendungen die <span class="marked">Betriebsmittel</span> zugänglich <br>
        -Abwicklung von Programmen steuern und überwachen <br>
        -Brücke zw. Hardware und Anwendungen
    </p>
    <h3>Betriebsmittel</h3>
    <p>
        Ressourcen des Rechensystems <br>
        Physikalische Betriebsmittel: Speicher, CPU, Geräte, ... <br>
        Logische Betriebsmittel: Fenster, Dateien, ...
    </p>
    <h3>Aufgaben</h3>
    <p>
        -Speicherverwaltung <br>
        -Scheduling <br>
        -Ressourcenverwalter <br>
    </p>
    <h3>Ziele</h3>
    <p>
        <span class="marked">Abstraktion:</span> Hardware-unabhängige Schnittstellen <br>
        <span class="marked">Effizienz:</span> Hardware-Ressourcen effektiv bereitstellen <br>
        <span class="marked">Zuverlässigkeit:</span> robustes Ausführen von Programmen <br>
        <span class="marked">Komfort:</span> einfaches Benutzen des Computers <br>
        <span class="marked">Sicherheit:</span> keine unerlaubten zugriffe <br>
        <span class="negativ">Zielkonflikte:
             Komfort vs. Effizienz, 
             Sicherheit vs. Schnelligkeit, ...</span>
    </p>
</div>

<div class="themeSection">
    <h2>
        Mikrokern vs. monolithischen Kern
    </h2>
    <h3>
        Mikrokern Betriebssystem
    </h3>
    <p>
        <span class="positiv">Vorteile:</span><br>
        -Sicherheit, Stabilität <br>
        -Flexiblität, Erweiterbarkeit<br>
        -Portierbarkeit<br>
        <span class="negativ">Nachteile:</span><br>
        -Langsamer (mehr Kontextwechsel nötig)<br>
        <br>
    <pre>
    +---------------------+
    |   Nutzerprozesse    |
    |  +---------------+  |
    |  |   Dienste     |  |
    |  +---------------+  |
    |  +---------------+  |
    |  |   Treiber     |  |
    |  +---------------+  |
    +---------------------+
    |      Mikrokern      |
    +---------------------+
    </pre>
    </p>
    <h3>
        Monolithischen Kernel Betriebssystem
    </h3>
    <p>
        <span class="positiv">Vorteile:</span><br>
        -Geschwindigkeit<br>
        <span class="negativ">Nachteile:</span><br>
        -Weniger Sicherheit<br>
        <br>
    <pre>
    +---------------------+
    |   Nutzerprozesse    |
    +---------------------+
    |                     |
    |                     |
    |    Monolithischer   |
    |       Kernel        |
    |                     |
    |                     |
    +---------------------+
    </pre>
    </p>
    
</div>

<div class="themeSection">
    <h2>
        Systemaufruf
    </h2>
    <p>
        Für sehr schnelle Ein- und Ausgaben will man das Umkopieren der Daten zwischen Userund Kernel-Mode vermeiden. Welcher Systemaufruf wird hierfür unter UNIX verwendet
        und was passiert dabei?
    </p>
</div>

<!--    SCHEDULING    -->
<h1>2. Scheduling</h1>

<div class="themeSection">
    <h2>
        Reentranter Code
    </h2>
    <p>
        -preemptiver CPU-Entzug kann jederzeit erfolgen <br>
        -von mehreren Threads gleichzeitig ausführbarer Code <br>
        -arbeitet korrekt egal wo unterbrochen <br>
        -muss ggf. synchronisiert werden <br>
        --globale Variablen vermeiden, weil werden geteilt auf Heap <br>
        --Zuständ des Threads als lokale var aufm Stack, da jeder Thread hat sein eigenen Stack <br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Prozess vs. Thread
    </h2>
    <h3>Prozess</h3>
    <p>
        -Programm in Ausführung<br>
        -Kann mehrere Threads enthalten, mind. 1<br>
        -Eigenen Adressraum<br>
        -Ressourcenintensiever<br>
        -Umschalten zwischen Prozessen langsamer(Chaches gespült, Adressraum laden...)<br>
        
    </p>
    <h3>Process Controll Block (PCB)</h3>
    <p>
        Verwaltet im Kernel-Space
    </p>
    <pre>
    +---------------------+
    |        PID          | -> Eindeutig
    +---------------------+
    |    Programmname     |
    +---------------------+
    |     Adressraum      |\
    +---------------------+ | -> Zustandsinformationen
    |   Betriebsmittel    |/-> geöffnete Dateien/Geräte, zum aufräumen
    +---------------------+
    |     Priorität       |
    +---------------------+
    |     UID und GID     |
    +---------------------+
    </pre>
    <h3>Thread</h3>
    <p>
        -Teil eines Prozesses<br>
        -unabhängig con anderen Threads ausführbar<br>
        -Hat eigenen Befehlszeiger(Programmfluss)<br>
        -Hat eigenen Stack<br>
        -Teilt sich Heap/Speicher und andere Ressourcen<br>
        -Leightwheigt Process<br>
        -Für nebenläufige verarbeitung, geht mit Prozessen(fork & pipes) aber schwergewichtig<br>
        -Warten auf I/O geräte, parallele Berechnung auf mehreren Cores, parallele Einzelaufgaben, http-Requests
    </p>
    <h3>Thread Controll Block (TCB)</h3>
    <p>
        Verwaltet im Kernel-Space
    </p>
    <pre>
    +---------------------+
    |        TID          |
    +---------------------+
    |    PCB *process     | -> Pointer auf PCB
    +---------------------+
    | Instruction Pointer |\
    +---------------------+ |
    |        Stack        | | -> Threadzustand (Register, gesichert)
    +---------------------+ |
    |  Weitere Register   |/
    +---------------------+
    |     Priorität       |
    +---------------------+
    |   Ausführungszeit   | -> Wie lange gerechnet
    +---------------------+
    </pre>
</div>

<div class="themeSection">
    <h2>
        Prioritätsinversion
    </h2>
    <p>
        <pan class="marked">Grund:</pan><br>
        Wenn ein Prozess mit niedriger Priorität eine Ressource exklusiv belegt hat,<br>
        die von einem Prozess mit höherer Priorität benötigt wird.<br>
        Dies führt dazu, dass der Job mit höherer Priorität warten muss und somit seine Priorität nicht mehr berücksichtigt wird.<br>
        <pan class="marked">Lösung:</pan><br>
        Eine Methode zur Behebung ist <span class="marked">Prioritätsvererbung</span><br>
        Hierbei erbt der Job mit niedriger Priorität vorübergehend die höhere <br>
        Priorität des wartenden Jobs und kann somit seine Arbeit schneller beenden und die Ressource freigeben.<br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Präemptiver Multitasking
    </h2>
    <p>
        Wie CPU entzogen?<br>
        “Context Switch”, bei dem der Zustand des aktuellen Prozesses gespeichert und der Zustand des nächsten Prozesses geladen wird.
    </p>
</div>

<div class="themeSection">
    <h2>
        Threadzustandsdiagramm
    </h2>
    <p>
        -Skizzieren
    </p>
</div>

<div class="themeSection">
    <h2>
        Completely Fair Scheduler
    </h2>
    <p>
        Linux verwendet unter anderem den Completely Fair Scheduler. Erklären Sie dessen Funktionsweise.
        Gehen Sie darauf ein, wie die rechenbereiten Threads verwaltet, wie ein Thread ausgewählt wird und
        wie die Prioriäten dynamisch angepasst werden
    </p>
</div>

<div class="themeSection">
    <h2>Ablaufplan</h2>
    <h3>Rate Monotonic Scheduling(RMS)</h3>
    <p>
        Wiederholen immer wieder
    </p>
    <h3>Round-Robin(RR)</h3>
    <p>
        Zeitscheibenverfahren danach abwechsekn
    </p>
    <h3>Earliest-Deadline-First(EDF)</h3>
    <p>
        Erste Deadline erster
    </p>
    <h3>Completely Fair Scheduler(CFS)</h3>
    <p>
        Erste Deadline erster
    </p>
    <p>
        -Reserve-Plan?
    </p>
    <p>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2223_Klausur1.pdf" target="blank">
            1. KLAUSUR 2023
        </a> 
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
            1. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_1.pdf" target="blank">
            1. KLAUSUR 2021
        </a>
    </p>
</div>


<!--   SPEICHERVERWALTUNG   -->
<h1>3. Speicherverwaltung</h1>

<div class="themeSection">
    <h2>
        Speicherhierarchie
    </h2>
    <p>
        Sekunder/Primärspeicher<br>
        Unterschiedliche Speicherarten in einem Computer(SSD, RAM, Cach, ...)<br>
        Persistenz, schnelligkeit, wahlfreier zugriff(Random Access), Sequentieller Zugriff(schneller), Kapazität
    </p>
    <h2>
        Anforderungen
    </h2>
    <p>
        Mehrprogrammbetrieb: Teilen sich Arbeitsspeicher<br>
        unklar welche/wie viele Programme geladen werden<br>
        <span class="marked">Zuteilung Speicherblöcke: </span> malloc, schnell, wenig Verschnitt<br>
        <span class="marked">Freigabe Speicherblöcke: </span> free, aufräumen beim Terminieren, manuelles/automatisches Einsammeln<br>
        Aus/Einlagern inaktiver Prozesse<br>
        <span class="marked">Relozierung: </span>mithilfe virtueller Speicherverwaltung Prozess an anderen adressen Einlagerbar machen<br>
    </p>
    <h2>
        Begriffe
    </h2>
    <p>
        <span class="marked">Speicherblock: </span>Menge fortlaufender Speicheradressen<br>
        <span class="marked">Partition: </span>Gesamtspeicherblock für Programm(nicht Festplatte Partition)<br>
        <span class="marked">Swapping: </span>Aus/Einlagern von Programmen/Partitionen auf Sekunderspeicher<br>
        <span class="marked">Physikalische(absolute) Speicheradresse: </span>zeigt in physisch vorhandenen Arbeitsspeicher<br>
        <span class="marked">Logische Speicheradresse: </span>Pos. im Arbeitsspeicher aus sicht des Programms, unabh. von phys. Speicherorganisation<br>
        <span class="marked">Relative Speicheradresse: </span>Pos. relativ zu einem bekannten Punkt im Programm(i.d.R. Instruction-Pointer)<br>
    </p>

    <h2>
        Partitionen im Arbeitsspeicher
    </h2>
    <p>
        Aufteilung des Arbeitsspeichers in gleich/variable große Partitionen für je ein Programm damit gleichzeitig ausführbar sind<br>
        Bestandteile:<br>
        <span class="marked">Stack: </span> Funktionsaufrufe(Parameter, lokale Var.)<br>
        <span class="marked">Heap: </span> Dyn. allozierte Daten(malloc), Heap Blöcke: Header(Länge, Flags, Anzahl eleArray, Typ Zeiger), Nutzdaten<br>
        <span class="marked">Globals: </span> globale Var.<br>
        <span class="marked">Text: </span> Code<br>
    </p>
    <h3>
        Statische Partitionierung
    </h3>
    <p>
        während Laufzeit nicht änderbar<br>
        Programm erhält kleinste in das es hineinpasst<br>
        Programm wartet in Zuteilungswarteschlange(für jede Patitionsgröße)<br>
        BS belegt auch eine Partition<br>
        <span class="positiv">Vorteil: </span>Einfach implementierbar, keine Externe Fragmentierung<br>
        <span class="negativ">Nachteil: </span>Max. #Prozesse statisch festgelegt, evt. passt Programm nirgends rein, Speicherbedarf eines Programms muss bekannt sein, Interne Fragmentierung<br>
    </p>
    <h3>
        Dynamische Partitionierung
    </h3>
    <p>
        Länge, Anzahl, Anfangsadressen der Partitionen ändert sich dynamisch<br>
        Programm erhält genauso viel Speicher wie benötigt<br>
        <span class="positiv">Vorteil: </span>Keine Interne Fragmentierung<br>
        <span class="negativ">Nachteil: </span>Externe Fragmentierung -> kann durch Neuanordungn behoben werden, aufwendig weil viele verschieben, gelöst durch virtuelle Speicherverwaltung<br>
    </p>

    <h2>
        Verwaltung freien Speichers
    </h2>
    <p>
        Bei Freigabe: prüfen ob Nachblöcke frei -> zusammenfassen<br>
    </p>
    <h3>
        Bitvektor/Bitmap
    </h3>
    <p>
        Speicher unterteilt(feste länge: 512B, 4KB)<br>
        Jeder bit repräsentiert ob einheit full oder nicht: 111001101111000101<br>
        Je kleiner einheit -> größer Bitvektor, Je größer -> interne Fragmentierung<br>
        <span class="positiv">Vorteil: </span>Kompakt<br>
        <span class="negativ">Nachteil: </span>Allokation langsam -> muss nach nullfolgen suchen<br>
    </p>
    <h3>
        Freispeichertabelle
    </h3>
    <p>
        Freie Blöcke in Tabelle verwaltet: Größe | Adresse<br>
        <span class="positiv">Vorteil: </span>Können var. längen haben <br>
    </p>

    <h3>
        Freispeicherliste(Beste)
    </h3>
    <p>
        Freie Heap-Blöcke mit Zeiger verkettet<br>
        evt. mehrere Listen für vers. größen<br>
        <span class="positiv">Vorteil: </span>Benötigt kein Speicher<br>
    </p>
    <h3>
        Buddy-System
    </h3>
    <p>
        <span class="marked">Buddys: </span>Zwei gleichgroße benachbarte blöcke<br>
        Speicher besteht asud 2^kmax Einheiten<br>
        Speichervergabe in Blockgrößen 2^k<br>
        Jeweils Liste für Blöcke der Größe 2^k<br>
        verw. Linux für Physikalische Speicher<br>
        <span class="positiv">Vorteil: </span>Schnelles verschmelzen<br>
        <span class="negativ">Nachteil: </span>interne u. externe Fragmentierung<br>
    </p>
    <h4>
        Allokation
    </h4>
    <p>
        1. Aufrunden auf nächste Zweierpotenz 1000Bytes -> 1024<br>
        2. Erstes freies Stück aus Liste 2^i<br>
        3. Falls 2^i leer(rekursiv): nächste Größe, halbieren, vordere hälfte zuteilen, hintere liste 2^i anhängen<br>
    </p>
    <h4>
        Freigabe
    </h4>
    <p>
        1. Buddy bestimmen<br>
        2. Falls belegt -> in liste einhängen, stoppen<br>
        3. Falls frei -> Vereinigen, gehe zu 1<br>
    </p>
    <h2>
        Auswahlstrategien freier Blöcke
    </h2>
    <p>
        Kriterien: Fragmentierung, Geschwindigkeit
    </p>
    <h3>
        First-Fit
    </h3>
    <p>
        nimmt ersten groß genug, evt. teilen, Ohne: interne Frag. Mit: externe Frag.<br>
        <span class="positiv">Vorteil: </span>Schnell<br>
        <span class="negativ">Nachteil: </span>Konzentration belegter stücke am Anfang<br>
    </p>
    <h3>
        Next-Fit
    </h3>
    <p>
        zyklisch durchlaufen: beginnt dort wo letzte aufgehört<br>
    </p>
    <h3>
        Best-Fit
    </h3>
    <p>
        Block der am wenigsten Speicherverschnitt verursacht<br>
        Freispeicherliste einmal komplett durchlaufen<br>
        <span class="negativ">Nachteil: </span>Bei zerschneidung seht kleine Stücke<br>
    </p>
    <h3>
        Worst-Fit
    </h3>
    <p>
        Nimm größten Block -> nach zerschneiden noch brauchbar
    </p>

    <h2>
        Interne und externe Fragmentierung/Verschnitt
    </h2>
    <h3>
        Interne Fragmentierung
    </h3>
    <p>
        Programm bekommt mehr speicher zugeteilt als nötig
    </p>
    <h3>
        Externe Fragmentierung
    </h3>
    <p>
        Kleine unbrauchbare Speicherblöcke bleiben übrig
    </p>
</div>

<div class="themeSection">
    <h2>
        Copy-On-Write Konzept
    </h2>
    <p>
        Was? <br>
        Wo? <br>
        Warum? <br>
    </p>
</div>

<div class="themeSection">
    <h2>
        Garbage Collection (Autom. Freispeichersammlung)
    </h2>
    <p>
        Garbage: Kein Pfad zwischen betrachteten Speicherblock und einem Wurzelzeiger<br>
        Nich adressiebare Blöcke autom. identifizieren u. freigeben(Programm oder Systemweit)<br>
        Expliziete Rückgabe durch Programmierer fehlerhaft und mühsam<br>
        -Abbau komplexer Struckturen<br>
        -Speicherlecks(Memory Leaks): vergessen freizugeben<br>
        -ungültige Zeiger(dangling pointers): zu früh<br>
    </p>
    <h3>
        GC-Phasen
    </h3>
    <p>
        1.Phase: Garbage Detection<br>
        2.Phase: Garbage Reclamation<br>
    </p>
    <h3>
        Vorraussetzungen
    </h3>
    <p>
        Referenzen müssen identifiezierbar sein<br>
        Typsichere Sprache<br>
        GC muss Aufbau eines Speicherblocks und der Stackframes kennen(Wo zeiger, wo andere Variablen)<br>
        -Die Info speichert Compiler in Symboltabelle
    </p>
    <h3>
        Wo Anfangen?
    </h3>
    <p>
        Bei Wurzel-Zeiger(root set): Menge aller gültigen Zeigervariablen, Zeiger in globalen Variablen, Alle Zeiger im Stack<br>
    </p>
    <h3>
        Mark & Sweep Algorithmus
    </h3>
    <p>
        Mark: Markiert alle erreichbaren Blöcke im Heap von Wurzelzeigern<br>
        Makierungsphase muss in einem Stück zu Ende laufen<br>
        werden im Header makiert<br>
        Für jeden Wurzelzeiger z:<br>
        Makiere(z)<br>

        <span class="positiv">Vorteil: </span>Einfach implementiert, Zyklen werden erkannt<br>
        <span class="negativ">Nachteil: </span>Tiefe Rekursion -> viel Speicher im Keller, Heap wird nicht kompaktiert<br>

        Makiere(block):<br>
         wenn block markiert dann beende funktion<br>
         block.mark = 1<br>
         für jeden block den block ref:<br>
         Markiere(block)<br>

        Sweep:<br>
        für jeden Block b, b.mark = 0:<br>
            Speicherfreigabe(b)<br>
        Skizze:
    </p>
    <img src="../../NotUsedImg/MarkAndSweep.png">
    <p>
        Vorraussetzung <br>
        Mithilfe Skizze wie Mark-And-Swepp-Collector funktioniert <br>
        beschreiben wie Copying-Collector funkt.
    </p>

    <h3>
        Inkrementeller Mark & Sweep Algorithmus
    </h3>
    <p>
        Nebenläufiges(unterbrechbar)<br>
        Blau: Block komplett untersucht<br>
        Rot: Noch nicht inspiziert<br>
        Grün: Bereits besucht aber nicht alle Nachfolger<br>
        Terminiert wenn keine grünen Blöcke mehr<br>
        Erfordert überwachung von Zeigerzuweisung(Wenn blauer block aufeinmal roten block ref.)<br>
    </p>
    <h3>
        Kopierende Freispeichersammlung
    </h3>
    <p>
        Heap in alt und neu unterteilen<br>
        Alle erreichbaren Blöcke rekursiv in neue Region kopieren<br>
        Garbage bleibt in alter Region<br>
        Bei nächsten GC-Aufruf tauschen<br>
        <span class="positiv">Vorteil: </span>Heap automatisch kompaktifiziert, Speicherallokation einfach(freier Speicher immer ein großer Block), Zyklen eliminiert<br>
        <span class="negativ">Nachteil: </span>Aufwändig viele kleine Blöcke zu kopieren, logische Adressraum halbiert, GC muss atomar komplett durchlaufen<br>
    </p>
    <h3>
        Inkrementeller Copying-Collector
    </h3>
    <p>
        Pro Aufruf vorgegebene Anzahl Blöcke kopieren(nicht zu lange Programm anhalten)<br>
        Iterative Lösung<br>
        Scan-Zeiger: Blöcke bis hier komplett abgearbeitet<br>
        Free-Zeiger: Blöcke zwischen den sind kopiert aber haben noch zeiger in die alte Region<br>
        kopierte alte Blöcke verweisen auf ihre Kopie<br>
        terminiert wenn scan auf free-zeiger trifft<br>
        <span class="positiv">Vorteil: </span>Heap automatisch kompaktifiziert, Speicherallokation einfach(freier Speicher immer ein großer Block), Zyklen eliminiert<br>
        <span class="negativ">Nachteil: </span>Zeigerzuweisung überwachen, Datenzugriffe auf kopierte Blöcke überwachen und syncen<br>
    </p>
    <h3>
        Reference Counting Algorithmus
    </h3>
    <p>
        Jeder Speicherblock hat Referenzzähler<br>
        Garbage wenn Referenzzähler auf null<br>
        Zeigerzuweisung über Laufzeitfunktion<br>
        <span class="positiv">Vorteil: </span>Inkrementelle GC möglich, Garbage sofort freigegeben, einfach implementierbar<br>
        <span class="negativ">Nachteil: </span>Zyklen(könnte ab und zu mark and sweep verwenden), erfordert Aufruf einer Laufzeitroutine<br>
    </p>
</div>


<div class="themeSection">
    <h2>
        Adressübersetzung
    </h2>
    <p>
        Bei x86-Prozessoren verwendet die Adressübersetzung bei aktiviertem
        Paging mehrstufige Seitentabellen. je einen Vor- und
        Nachteil im Vergleich zu einer einstufigen Adressübersetzung.
    </p>
</div>

<div class="themeSection">
    <h2>
        Lokalitätsprinzip
    </h2>
    <p>
        Warscheinlich ist das Dateien gelesen werden die nah beieinander sind <br>
        => Cachen
    </p>
</div>

<div class="themeSection">
    <h2>
        Übersetzung virtueller Adressen zu physikalischen Adressen <br>
        mit Page-Directories/Page-Tables
    </h2>
    <p>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
        <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
    </p>
</div>

<div class="themeSection">
    <h2>
        Addess Space Layout Randomization (ASLR)
    </h2>
    <p>
        Alle Adressen randomisiert per flag beim compilieren<br>
        Was? <br>
        Wieso wurde das Konzept eingeführt?
    </p>
</div>

<div class="themeSection">
    <h2>
        Partition
    </h2>
    <p>
        In Betriebssystemen ohne virtuelle Speicherverwaltung werden einzelnen 
        Programmen sogenannte Partitionen zugeteilt. Skizzieren und erläutern Sie (4 P.)
        den Inhalt einer Partition.
    </p>
</div>

<div class="themeSection">
    <h2>
        MMU
    </h2>
    <p>
        Muss die MMU bei aktiviertem Paging für die Adressberechnung immer auf die Seiten-Tabellen
        im Hauptspeicher zugreifen?
    </p>
</div>

<div class="themeSection">
    <h2>
        Schutzarten Paging x86-Prozessoren
    </h2>
    <p>
        Drei Schutzarten
    </p>
</div>



<!--   DATEISYSTEME   -->
<h1>4. Dateisysteme</h1>
<div class="themeSection">
    <h2>
        Inodes
    </h2>
    <p>
        -Inhalt in einem klassichen UNIX-Dateisystem
    </p>    
</div>

<div class="themeSection">
    <h2>
        NTFS
    </h2>
    <p>
        Welche vier Bestandteile speichert NTFS für eine kurze Datei? <br>
        Wie speichert NTFS eine große Datei? Zeichnen Sie dazu auch ein Bild.
    </p>        
</div>

<div class="themeSection">
    <h2>
        Struktur ext2 Partition <br>
        Struktur FAT16 Partition
    </h2>
    <p>
        Skizzieren und erläutern
    </p>        
</div>

<div class="themeSection">
    <h2>
        UNIX-Dateisystemstrukturen
    </h2>
    <p>
        Zeichen: Inodes und Datenblöcke <br>
        für abgebildeten Dateisystembaum <br>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
            2. KLAUSUR 2022
        </a>
    </p>        
</div>

<div class="themeSection">
    <h2>
        UNIX-Dateisysteme
    </h2>
    <p>
        -Welche Semantik hat das Setuid-Bit in UNIX-Dateisystemen? Warum (2 P.)
        sollte dieses Bit aus Sicherheitsgründen nur selten verwendet werden? <br>
        -Im Dateisystem ext4 werden sogenannte Extents verwendet. Erklären Sie, (2 P.) 
        welche Informationen für einen Extent gespeichert werden und nennen Sie 
        einen Vorteil gegenüber der klassischen Multilevel-Index-Allokation 
        (Inodes mit je einem Zeiger auf einen Block) <br>
        -Inhalt eines Inodes einem klassischen UNIX-Dateisystem <br>
        -Im Dateisystem ext4 werden sogenannte Extents verwendet. Erklären Sie, welche Informationen für einen Extent gespeichert werden und nennen Sie einen Vorteil gegenüber der
        klassischen Multilevel-Index-Allokation (Inodes mit je einem Zeiger auf einen Block
    </p>        
</div>

<div class="themeSection">
    <h2>
        FAT16
    </h2>
    <p>
        -Skizzieren Struktur FAT16-Partition <br>
        -Erstellen Sie 
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
            1. Klausur 2022 
            -für den gegebenen Ausschnitt einen Auszug der FAT16-Tabelle, welche 
            die Datei sowie die leeren als auch die defekten nachstehenden Cluster zeigt.
        </a>
    </p>        
</div>


<!--   SYNCHRONISIERUNG   -->
<h1>5. Synchronisierung</h1>
<div class="themeSection">
    <h2>
        Kritische Abschnitte
    </h2>
    <p>
        <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
            2. KLAUSUR 2021
        </a>
    </p>        
</div>

<div class="themeSection">
    <h2>
        Leser-Schreiber-Problem, Semaphor-Variablen
    </h2>
    <p>
    
    </p>        
</div>


<!--   PROGRAMMIERAUFGABE  -->
<h1>6. Programmieraufgabe</h1>
<p>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2223_Klausur1.pdf" target="blank">
        1. KLAUSUR 2023
    </a> 
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur2.pdf" target="blank">
        2. KLAUSUR 2022
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2122_Klausur1.pdf" target="blank">
        1. KLAUSUR 2022
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_2.pdf" target="blank">
        2. KLAUSUR 2021
    </a>
    <br>
    <a href="https://coconucos.cs.uni-duesseldorf.de/lehre/klausuren/BS_Klausuren/BSuSP_WS2021_Klausur_1.pdf" target="blank">
        1. KLAUSUR 2021
    </a>
</p>
</body>
</html>